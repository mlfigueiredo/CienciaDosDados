{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mlfigueiredo/CienciaDosDados/blob/main/PLN%20demonstra%C3%A7%C3%A3o.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Imports\n",
        "import nltk\n",
        "nltk.download('webtext')\n",
        "from nltk.corpus import webtext\n",
        "\n",
        "#Fileids\n",
        "print(\"\\n\")\n",
        "print(webtext.fileids())\n",
        "\n",
        "# Distribuição de frequência de um único arquivo\n",
        "fileid = 'singles.txt'\n",
        "wbt_words = webtext.words(fileid)\n",
        "fdist = nltk.FreqDist(wbt_words)\n",
        "\n",
        "# Report\n",
        "print('\\nContagem do número máximo de ocorrências do token \"',fdist.max(),'\" : ', fdist[fdist.max()])\n",
        "print('\\nNúmero total de tokens distintos : ', fdist.N())\n",
        "print('\\nA seguir estão os 10 tokens mais comuns')\n",
        "print(fdist.most_common(20))\n",
        "print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oYSf-e7DPTAf",
        "outputId": "83ee48d8-d13b-4817-d684-4711b63fd2cd"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "['firefox.txt', 'grail.txt', 'overheard.txt', 'pirates.txt', 'singles.txt', 'wine.txt']\n",
            "\n",
            "Contagem do número máximo de ocorrências do token \" , \" :  539\n",
            "\n",
            "Número total de tokens distintos :  4867\n",
            "\n",
            "A seguir estão os 10 tokens mais comuns\n",
            "[(',', 539), ('.', 353), ('/', 110), ('for', 99), ('and', 74), ('to', 74), ('lady', 68), ('-', 66), ('seeks', 60), ('a', 52), ('with', 44), ('S', 36), ('ship', 33), ('&', 30), ('relationship', 29), ('fun', 28), ('in', 27), ('slim', 27), ('build', 27), ('o', 26)]\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package webtext to /root/nltk_data...\n",
            "[nltk_data]   Package webtext is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Texto\n",
        "frase = \"Aprendendo processamento linguagem natural. Python e NLTK facilitam nossa vida!. Meu nome é Marcos Leandro Figueiredo\"\n",
        "\n",
        "# Tokenization em sentenças\n",
        "sent_tokens = sent_tokenize(frase)\n",
        "print(sent_tokens)\n",
        "\n",
        "word_tokens = word_tokenize(frase)\n",
        "print('\\n\\n',word_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "orX36IR_PTDO",
        "outputId": "59dd037d-0029-47d9-ff93-47998d43df4a"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Aprendendo processamento linguagem natural.', 'Python e NLTK facilitam nossa vida!.', 'Meu nome é Marcos Leandro Figueiredo']\n",
            "\n",
            "\n",
            " ['Aprendendo', 'processamento', 'linguagem', 'natural', '.', 'Python', 'e', 'NLTK', 'facilitam', 'nossa', 'vida', '!', '.', 'Meu', 'nome', 'é', 'Marcos', 'Leandro', 'Figueiredo']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "english_stops = set(stopwords.words('english'))\n",
        "\n",
        "print(english_stops)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sJkfGDRbPTGN",
        "outputId": "c63ee70c-6308-4558-9634-aa0ff9baef5e"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'herself', 'at', 's', 'is', 'was', 'only', 'mustn', 'our', 'before', 'more', \"hasn't\", 'own', \"should've\", 'now', 'mightn', 'will', 'you', \"you're\", 'each', \"won't\", 'where', 'during', \"couldn't\", 'shouldn', \"wouldn't\", 'yourself', 'under', 'needn', 'her', 'wasn', 'am', 'were', 'm', 'isn', 'hers', 'd', 'into', 'should', 'she', 'i', 'won', 'didn', 'few', 'about', 'himself', 'both', 'through', 'myself', 'further', 'ain', 'can', 'that', 'yours', 'has', 'theirs', \"don't\", 'hadn', 'while', 'weren', 'those', 'between', 'too', 'until', 'by', 'which', 'below', 'o', 't', 'ourselves', 'aren', 'themselves', 'don', \"that'll\", 'above', 'them', 'no', 'are', \"mustn't\", 'he', 'be', 'not', 'his', 'in', \"it's\", 'have', 'so', 'nor', 'if', 'an', \"weren't\", 'been', \"needn't\", 'after', 'did', \"shouldn't\", 'couldn', \"you'd\", 'my', 'very', 'whom', 'ours', 'or', 'do', 'then', 'why', 'down', \"aren't\", \"isn't\", 'its', 'for', \"she's\", 'other', 'how', 'once', 'than', 'doing', \"shan't\", 'had', 'up', 'hasn', 'your', 'there', 'out', 'shan', 'against', 'off', 'because', 'haven', 'any', 'here', 'they', 'with', 'we', 'as', 'and', 'having', \"you've\", 'this', \"wasn't\", 'on', 'from', \"mightn't\", 'of', 'when', 'their', 'just', 'll', 'who', 'some', 'yourselves', 'over', 're', 've', 'what', 'but', 'the', 'most', 'to', 'him', \"didn't\", 'y', 'again', 'these', 'all', 'ma', 'being', 'a', \"hadn't\", 'does', 'me', 'same', \"haven't\", \"doesn't\", 'itself', 'it', \"you'll\", 'doesn', 'such', 'wouldn'}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "portuguese_stops = set(stopwords.words('portuguese'))\n",
        "palavras = [\"Estou\", 'estudando', 'sobre', 'um', 'tema', 'interesante', 'em', 'PLN']\n",
        "print([palavra for palavra in palavras if palavra not in portuguese_stops])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r29pk-oPXxp0",
        "outputId": "aafbe789-dda6-4d6e-e397-f2f0baeeb2c4"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Estou', 'estudando', 'sobre', 'tema', 'interesante', 'PLN']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#técnica de remoção de sufixos e prefixos numa palavra, pois a título de PLN, eles não tem importância nenhuma.\n",
        "#Essa técnica é chamada de Stemming. Existem vários tipos de Stemming no NLTK\n",
        "# Import\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem import LancasterStemmer\n",
        "\n",
        "# Cria o Stemmer\n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "# Aplica o Stemmer\n",
        "print(\"\\nPorterStemmer\")\n",
        "print(stemmer.stem('studing'))\n",
        "print(stemmer.stem('studied'))\n",
        "\n",
        "# Cria o Stemmer\n",
        "stemmer2 = LancasterStemmer()\n",
        "\n",
        "# Aplica o Stemmer\n",
        "print(\"\\nLancasterStemmer\")\n",
        "print(stemmer2.stem('studing'))\n",
        "print(stemmer2.stem('studied'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x5is0AxHXxsj",
        "outputId": "d9fb2d69-d845-4bd6-d22e-36de7f2c93b7"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "PorterStemmer\n",
            "stude\n",
            "studi\n",
            "\n",
            "LancasterStemmer\n",
            "stud\n",
            "study\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "q9ycw4utXxvy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "b_pZ_FRPPTI9"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Damos-lhe as boas-vindas ao Colaboratory",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}