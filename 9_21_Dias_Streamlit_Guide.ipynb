{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mlfigueiredo/CienciaDosDados/blob/main/9_21_Dias_Streamlit_Guide.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Streamlit Guide**"
      ],
      "metadata": {
        "id": "gVVV7vHCsVuk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instalar o Pacote\n",
        "!pip install streamlit"
      ],
      "metadata": {
        "id": "IKvaPUQZdH5s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "KTnMehCKdE7j"
      },
      "outputs": [],
      "source": [
        "# Criar a Máquina Preditiva\n",
        "# Esta célula fica no 1º google colab\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import random\n",
        "from sklearn.metrics import accuracy_score\n",
        "import pickle\n",
        "data = load_iris()\n",
        "X = data.data\n",
        "y = data.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=10)\n",
        "#Criar a Máquina Preditiva com Algoritmo de Machine Learning\n",
        "clf = LogisticRegression(C=0.01)\n",
        "clf.fit(X_train, y_train)\n",
        "pickle.dump(clf, open('final_model1.sav', 'wb'))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(data)"
      ],
      "metadata": {
        "id": "O_pt7t33bOPT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Criar arquivos Python de Automação - model_methods.py\n",
        "# Esta celula, copio e colo em uma 2ª aba do google colab sem o .ipynb, que cria a função predict para novos dados.\n",
        "# Vou salvar e fazer o download .py ==> Transferir - .py\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import pickle\n",
        "\n",
        "def predict(arr):\n",
        "    # Load the model\n",
        "    with open('final_model.sav', 'rb') as f:\n",
        "        model = pickle.load(f)\n",
        "    classes = {0:'Iris Setosa',1:'Iris Versicolor',2:'Iris Virginica'}\n",
        "    # return prediction as well as class probabilities\n",
        "    preds = model.predict_proba([arr])[0]\n",
        "    return (classes[np.argmax(preds)], preds)"
      ],
      "metadata": {
        "id": "fjlkpFlIdaj4"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Criar o arquivo de Inicialização do Aplicativo - app.py\n",
        "# Vou inserir na 3ª aba do google colab e vou salvar e download do .py ==> Transferir - .py\n",
        "# Vou ter três arquivos: final_model1.sav, model_methods.py e app.py\n",
        "# Vou colocar os três arquivos em uma pasta do windows e abrir a IDE VisualStudioCode. Setar a minha pasta com meus 3 arquivos\n",
        "\n",
        "import streamlit as st\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from model_methods import predict\n",
        "classes = {0:'setosa',1:'versicolor',2:'virginica'}\n",
        "class_labels = list(classes.values())\n",
        "st.title(\"Tipificação das Espécies de Plantas\")\n",
        "st.markdown('**Objetivo** : Dadas as características das flores vamos prever a especie da flor.')\n",
        "st.markdown('A Máquina Preditiva pode prever se a planta pertence às três categorias a seguir : **setosa, versicolor, virginica** ')\n",
        "\n",
        "def predict_class():\n",
        "    data = list(map(float,[sepal_length,sepal_width,petal_length, petal_width]))\n",
        "    result, probs = predict(data)\n",
        "    st.write(\"A planta é do tipo \",result)\n",
        "    probs = [np.round(x,6) for x in probs]\n",
        "\n",
        "    ax = sns.barplot(probs ,class_labels, palette=\"winter\", orient='h')\n",
        "\n",
        "    ax.set_yticklabels(class_labels,rotation=0)\n",
        "\n",
        "    plt.title(\"Probabilidades dos Dados pertencentes a cada classe\")\n",
        "\n",
        "    for index, value in enumerate(probs):\n",
        "        plt.text(value, index,str(value))\n",
        "    st.pyplot()\n",
        "    \n",
        "st.markdown(\"**Por favor, insira os detalhes da flor na forma de 4 valores decimais separados por vírgulas**\")\n",
        "sepal_length = st.text_input('Valor do sepal_length', '')\n",
        "sepal_width = st.text_input('Valor do sepal_width', '')\n",
        "petal_length = st.text_input('Valor do petal_length', '')\n",
        "petal_width = st.text_input('Valor do petal_width', '')\n",
        "\n",
        "if st.button(\"Previsão\"):\n",
        "    predict_class()\n"
      ],
      "metadata": {
        "id": "ikV1fNf8dgy5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}